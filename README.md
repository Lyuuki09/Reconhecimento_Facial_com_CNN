# üöÄ Sistema de Reconhecimento Facial Inteligente com PyTorch üß†

---

## ‚ú® Vis√£o Geral do Projeto

Este projeto tem como objetivo principal desenvolver um sistema robusto de reconhecimento facial utilizando as capacidades avan√ßadas do PyTorch e Redes Neurais Convolucionais (CNNs). Al√©m do reconhecimento padr√£o, o sistema incorpora uma funcionalidade inovadora de **cadastro incremental de usu√°rios**, permitindo a inclus√£o de novas identidades sem a necessidade de retreinar o modelo do zero.

### üéØ Objetivo Principal (do Professor)

Desenvolver um sistema de reconhecimento facial utilizando PyTorch e redes neurais convolucionais (CNN). O foco do projeto √© aplicar CNNs, com ou sem transfer learning, para identifica√ß√£o de pessoas a partir de imagens de rosto.

### üìú Regras e Restri√ß√µes T√©cnicas (do Professor)

- O projeto deve ser implementado com PyTorch.
- A arquitetura deve obrigatoriamente utilizar redes convolucionais (CNN).
- √â permitido o uso de modelos pr√©-treinados como ResNet, VGGFace, FaceNet, EfficientNet, etc.
- S√£o aceitas tanto abordagens de classifica√ß√£o direta (com imagens de rostos recortados) quanto de detec√ß√£o de objetos, como YOLO.
- Pode-se usar bibliotecas como OpenCV, MTCNN, MediaPipe, ou YOLO para detec√ß√£o facial.
- A entrada do modelo pode ser a imagem completa ou o recorte facial, conforme a abordagem adotada.

### ‚úÖ Requisitos Funcionais (do Professor)

- O sistema deve reconhecer corretamente cada participante com base em uma imagem contendo seu rosto.
- A entrada pode ser uma imagem com um ou mais rostos.
- A sa√≠da deve indicar o nome ou r√≥tulo da pessoa reconhecida.

---

## üõ†Ô∏è Detalhes da Implementa√ß√£o

Aqui, detalhamos o cora√ß√£o t√©cnico do nosso sistema.

### üèóÔ∏è Arquitetura da Rede Neural

Nosso sistema utiliza uma **Rede Neural Convolucional (CNN)** baseada na arquitetura pr√©-treinada **ResNet18**. A ResNet18 √© conhecida por sua efici√™ncia e capacidade de aprender representa√ß√µes hier√°rquicas complexas de imagens.

- **Backbone**: ResNet18 pr√©-treinada em ImageNet. As camadas iniciais (backbone) s√£o congeladas durante o fine-tuning para preservar o conhecimento de caracter√≠sticas gerais.
- **Embedding Head**: Uma camada convolucional e/ou linear adicional (`nn.Sequential` em `ImprovedFaceRecognitionModel`) que mapeia as features extra√≠das pelo backbone para um vetor de embedding de tamanho `EMBEDDING_SIZE` (512 no nosso caso). Este embedding serve como uma representa√ß√£o num√©rica √∫nica do rosto.
- **Classificador**: Uma camada linear final que mapeia o vetor de embedding para o n√∫mero de classes (pessoas) presentes no dataset. Esta camada √© adaptada dinamicamente quando novos usu√°rios s√£o cadastrados.

### ‚öôÔ∏è Estrat√©gia de Pr√©-processamento e Treinamento

Nosso pipeline de treinamento √© cuidadosamente projetado para otimizar o aprendizado e a adaptabilidade do modelo.

#### Pr√©-processamento de Imagens

As imagens passam por um pipeline de pr√©-processamento robusto:
1.  **Redimensionamento**: Todas as imagens s√£o redimensionadas para `224x224` pixels, o tamanho de entrada esperado pela ResNet18.
2.  **Convers√£o para Tensor**: Imagens s√£o convertidas para tensores PyTorch.
3.  **Normaliza√ß√£o**: Aplicamos a normaliza√ß√£o padr√£o da ImageNet (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`) para alinhar a distribui√ß√£o dos pixels com os dados em que o modelo foi pr√©-treinado.
4.  **Carregamento de Imagens Seguras**: Para lidar com caminhos de arquivo que contenham caracteres especiais (comuns no Windows), utilizamos a biblioteca `Pillow` (`PIL.Image.open`) para carregar as imagens, que √© mais robusta que `cv2.imread` para esses casos.

#### Treinamento do Modelo

-   **Otimizador**: `AdamW` √© utilizado como otimizador, conhecido por sua boa performance e tratamento de decaimento de peso.
-   **Taxa de Aprendizado (Learning Rate)**: `LEARNING_RATE = 0.0001` para o treinamento inicial.
-   **Agendador de Taxa de Aprendizado (Scheduler)**: `ReduceLROnPlateau` monitora a acur√°cia de valida√ß√£o. Se a acur√°cia n√£o melhorar por um determinado n√∫mero de √©pocas (`patience`), a taxa de aprendizado √© reduzida, ajudando o modelo a convergir.
-   **Crit√©rio de Perda (Loss Function)**: `nn.CrossEntropyLoss` √© usada para classifica√ß√£o multi-classe.
-   **√âpocas**: Definido como `EPOCHS = 1` para testes r√°pidos. Para um modelo robusto, um n√∫mero maior de √©pocas (e.g., 20-50) seria necess√°rio.
-   **Early Stopping**: Um mecanismo de early stopping com `patience = 15` monitora a acur√°cia de valida√ß√£o para evitar overfitting, parando o treinamento se a performance n√£o melhorar.

### üìà Resultados do Treinamento

Ap√≥s o treinamento, o sistema salva o modelo com a melhor acur√°cia de valida√ß√£o. Os resultados incluem:

-   **Acur√°cia de Treinamento e Valida√ß√£o**: Monitoradas ao longo das √©pocas.
-   **Perda de Treinamento**: Monitorada para verificar a converg√™ncia.
-   **Matriz de Confus√£o**: Uma matriz de confus√£o √© gerada e salva (ou exibida) para visualizar o desempenho do classificador em cada classe, identificando erros e acertos.

---

## ‚ûï Adicional: MVP para Cadastro Incremental de Usu√°rios

Este √© um diferencial crucial do nosso projeto, permitindo a **evolu√ß√£o cont√≠nua** do sistema.

### üéØ Objetivo (do Professor)

Permitir a inclus√£o de novos usu√°rios no sistema de reconhecimento facial sem apagar ou sobrescrever os usu√°rios j√° cadastrados.

### üìã Requisitos T√©cnicos (do Professor)

- O sistema deve armazenar as representa√ß√µes faciais dos usu√°rios (por exemplo, vetores de embeddings ou imagens associadas aos r√≥tulos).
    - **Nossa Abordagem**: Armazenamos as imagens diretamente em diret√≥rios nomeados e o modelo aprende os embeddings internamente.
- O cadastro pode ser feito a partir de uma ou mais imagens do novo usu√°rio.
    - **Nossa Abordagem**: A interface permite upload de m√∫ltiplas imagens.
- O modelo pode:
    - Atualizar um banco de embeddings, se a arquitetura utilizar essa abordagem.
    - Utilizar fine-tuning leve ou incremental em uma rede existente, se necess√°rio.
        - **Nossa Abordagem**: Utilizamos fine-tuning leve.
    - Atualizar um banco de dados com imagens e r√≥tulos, e reprocessar conforme necess√°rio.
        - **Nossa Abordagem**: As imagens s√£o copiadas para as pastas de `Fotos/` e o mapeamento de labels (`label_mapping_fixed.json`) √© atualizado.

### üöÄ Funcionalidades Implementadas (no MVP)

-   **Interface Gr√°fica Simples (Streamlit)**: Uma se√ß√£o dedicada no `app.py` permite que o usu√°rio insira o nome da nova pessoa e fa√ßa upload de suas imagens.
-   **Associa√ß√£o Nome/R√≥tulo**: As imagens s√£o salvas em uma pasta com o nome do usu√°rio, e o sistema automaticamente associa este nome a uma nova classe/r√≥tulo.
-   **Fine-tuning Leve**:
    1.  O modelo pr√©-treinado √© carregado.
    2.  Se houver uma nova classe (novo usu√°rio), a camada classificadora final do modelo √© adaptada para incluir essa nova classe.
    3.  As camadas do **backbone (ResNet18) s√£o congeladas**. Isso impede que os pesos das caracter√≠sticas gerais sejam alterados.
    4.  Apenas o **embedding head e a nova camada classificadora s√£o treinados** (descongelados) com uma taxa de aprendizado menor. Isso acelera o treinamento e foca na adapta√ß√£o √†s novas identidades.
-   **Garantia de Reconhecimento Anterior**: A estrat√©gia de fine-tuning leve minimiza o impacto no reconhecimento de usu√°rios j√° cadastrados, pois o conhecimento pr√©-existente do backbone √© preservado. Testes pr√°ticos ap√≥s a inclus√£o de novos usu√°rios s√£o recomendados para validar isso.
-   **Registro Persistente**: O modelo treinado (`face_recognition_model_fixed.pt`) e o mapeamento de labels (`label_mapping_fixed.json`) s√£o salvos e atualizados ap√≥s cada processo de fine-tuning, garantindo que as informa√ß√µes dos novos usu√°rios sejam mantidas.

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

1.  **Clone este reposit√≥rio:**
    ```bash
    git clone [URL_DO_REPOSITORIO]
    cd [NOME_DO_DIRETORIO]
    ```

2.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Para o treinamento inicial do modelo:**
    (Este passo √© necess√°rio uma vez para gerar o modelo base antes de usar a interface Streamlit)
    ```bash
    python rooney_trabalho.py
    ```

---

## üöÄ Como Usar a Aplica√ß√£o

1.  **Inicie a aplica√ß√£o Streamlit:**
    ```bash
    streamlit run app.py
    ```
    A interface web ser√° aberta automaticamente no seu navegador padr√£o.

2.  **Funcionalidades na Interface:**
    -   **Reconhecimento Facial**: Fa√ßa upload de uma imagem contendo um rosto para que o sistema tente identific√°-lo.
    -   **Cadastro Incremental de Novos Usu√°rios**:
        1.  Na se√ß√£o "Cadastro Incremental de Novos Usu√°rios", digite o **Nome do Novo Usu√°rio**.
        2.  Fa√ßa upload de **pelo menos 5 imagens** do novo usu√°rio (quanto mais imagens de boa qualidade, melhor a performance).
        3.  Clique em "**Cadastrar Novo Usu√°rio e Fine-tune**".
        4.  Aguarde o processo de fine-tuning (pode levar alguns minutos).
        5.  **Importante**: Ap√≥s o cadastro, **recarregue a p√°gina do Streamlit** no seu navegador para que o novo modelo (com as novas classes) seja carregado e utilizado para reconhecimento.

---

## üí° Dicas para Melhor Performance

-   **Qualidade das Imagens**: Use imagens de boa qualidade para o cadastro e reconhecimento.
-   **N√∫mero de Imagens**: Forne√ßa pelo menos 5-10 imagens distintas por usu√°rio para o cadastro (quanto mais, melhor).
-   **Ilumina√ß√£o e Posi√ß√£o**: Certifique-se de que as imagens tenham boa ilumina√ß√£o e que o rosto esteja bem vis√≠vel.
-   **Recorte Facial**: Embora o sistema lide com redimensionamento, imagens com rostos bem enquadrados e centralizados tendem a performar melhor.

---

## ‚ÅâÔ∏è Solu√ß√£o de Problemas Comuns

1.  **`ModuleNotFoundError`**: Certifique-se de que todas as depend√™ncias em `requirements.txt` est√£o instaladas e que o ambiente virtual est√° ativado. Renomeie `Rooney trabalho.py` para `rooney_trabalho.py` se ainda n√£o o fez.
2.  **`expected scalar type Double but found Float`**: Execute `python rooney_trabalho.py` para retreinar o modelo com a precis√£o correta antes de rodar `streamlit run app.py`.
3.  **Erro ao Carregar Imagens (`cv2.imread` falha com caracteres especiais)**: A solu√ß√£o com `Pillow` foi implementada. Verifique se as imagens n√£o est√£o corrompidas.
4.  **Erro de CUDA**: Se voc√™ n√£o tiver uma GPU NVIDIA, o sistema funcionar√° em CPU, mas ser√° mais lento. Certifique-se de que as bibliotecas `torch` e `torchvision` foram instaladas para CPU se n√£o tiver CUDA.
5.  **Webcam n√£o funciona**: Certifique-se de que sua webcam est√° funcionando e acess√≠vel por outros aplicativos. Permiss√µes do navegador podem ser necess√°rias. (Se voc√™ adicionar a funcionalidade de webcam).
6.  **Erros de Mem√≥ria**: Se encontrar erros de mem√≥ria, tente reduzir o `BATCH_SIZE` em `rooney_trabalho.py` ou o n√∫mero de `num_workers` nos `DataLoader`s.

---

## üìÇ Estrutura de Diret√≥rios

```
projeto/
‚îú‚îÄ‚îÄ app.py                     # üöÄ Interface web principal (Streamlit)
‚îú‚îÄ‚îÄ rooney_trabalho.py         # üß† Core do sistema: modelo, treinamento e fine-tuning
‚îú‚îÄ‚îÄ requirements.txt           # üì¶ Depend√™ncias do Python
‚îú‚îÄ‚îÄ .gitignore                 # üö´ Arquivos e diret√≥rios a serem ignorados pelo Git
‚îú‚îÄ‚îÄ README.md                  # üìÑ Este arquivo: documenta√ß√£o do projeto
‚îî‚îÄ‚îÄ data/                      # üóÉÔ∏è Diret√≥rio para dados do projeto
    ‚îú‚îÄ‚îÄ raw/                   # üì∏ Imagens originais dos usu√°rios (mant√©m subpastas por pessoa)
    ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
    ‚îú‚îÄ‚îÄ processed/             # ‚ú® Imagens pr√©-processadas (geradas, se aplic√°vel)
    ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
    ‚îî‚îÄ‚îÄ models/                # üíæ Modelos PyTorch treinados e mapeamentos
        ‚îî‚îÄ‚îÄ .gitkeep
```

---

## ü§ù Contribuindo

Sinta-se √† vontade para abrir [issues]([URL_DO_REPOSITORIO]/issues) para relatar bugs ou sugerir melhorias, ou enviar [pull requests]([URL_DO_REPOSITORIO]/pulls) com novas funcionalidades.

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa [MIT License](https://opensource.org/licenses/MIT). 